{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b279425-dc70-4b8d-aee3-c225595170b1",
   "metadata": {},
   "source": [
    "# 20 뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48250175-b7e3-427a-868b-1a1677620d85",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f57d4c4-596f-4dbc-98e9-496d750bb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_20newsgroups: 20개의 주제에 대한 18,846개의 뉴스 데이터\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "# subset: 로드할 데이터 세트를 선택\n",
    "# 훈련 세트는 'train', 테스트 세트는 'test', 둘 다는 'all'\n",
    "news_data = fetch_20newsgroups(subset='all', random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9671c3b1-3a16-486a-9756-711160626376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "(18846,)\n"
     ]
    }
   ],
   "source": [
    "print(type(news_data))\n",
    "print(np.array(news_data.data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32348b53-b0a5-4dcd-8701-918aa8d161ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포\n",
      "{'alt.atheism': 799, 'comp.graphics': 973, 'comp.os.ms-windows.misc': 985, 'comp.sys.ibm.pc.hardware': 982, 'comp.sys.mac.hardware': 963, 'comp.windows.x': 988, 'misc.forsale': 975, 'rec.autos': 990, 'rec.motorcycles': 996, 'rec.sport.baseball': 994, 'rec.sport.hockey': 999, 'sci.crypt': 991, 'sci.electronics': 984, 'sci.med': 990, 'sci.space': 987, 'soc.religion.christian': 997, 'talk.politics.guns': 910, 'talk.politics.mideast': 940, 'talk.politics.misc': 775, 'talk.religion.misc': 628}\n"
     ]
    }
   ],
   "source": [
    "print('target 클래스의 값과 분포')\n",
    "print(dict(zip(np.unique(news_data.target_names), np.bincount(news_data.target))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bfb38b-179d-40f2-b2af-79879ae39a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: ggr@koonda.acci.com.au (Greg Rose)\n",
      "Subject: Authentication and one-time-pads (was: Re: Advanced one time pad)\n",
      "Summary: presents one-time-pad based MAC\n",
      "Organization: Australian Computing and Communications Institute\n",
      "Lines: 93\n",
      "\n",
      "In article <1s1dbmINNehb@elang05.acslab.umbc.edu> olson@umbc.edu (Bryan Olson; CMSC (G)) writes:\n",
      ">The one-time-pad yeilds ideal security, but has a well-known flaw in\n",
      ">authentication.  Suppose you use a random bit stream as the pad, and\n",
      ">exclusive-or as the encryption operation.  If an adversary knows the \n",
      ">plaintext of a message, he can change it into any other message.  \n",
      ">Here's how it works.\n",
      ">\n",
      ">Alice is sending Bob a plaintext P, under a key stream S\n",
      ">Alice computes the ciphertext C = S xor P,  and sends it to Bob.\n",
      ">\n",
      ">Eve knows the plainext P, but wants the message to appear as P'.\n",
      ">Eve intercepts C, and computes  C' = C xor P xor P' = S xor P'.\n",
      ">Eve sends C' to Bob.\n",
      ">\n",
      ">Bob decrypts C' by computing  C'xor S = P',  thus receiving the \n",
      ">false message which was substituted by Eve.\n",
      "\n",
      "Firstly, an aside:\n",
      "\n",
      "I agree that the weakness exists, but I have a lot of trouble\n",
      "believing that it represents a difficulty in real life. Given:\n",
      "\n",
      "1. the purpose of the one-time pad is to give unbreakable security,\n",
      "and the expense of key distribution etc., imply that the clients\n",
      "really do want that level of security\n",
      "\n",
      "2. These same people want to keep P a secret\n",
      "\n",
      "I find it hard to believe that Eve might happen to have a copy of P\n",
      "lying around.\n",
      "\n",
      "(I am aware that the same argument applies to Eve knowing even a small\n",
      "part of the message, but Eve must know EXACTLY where (which bytes) in\n",
      "C her known susequence starts, or the result will be garbled. I find\n",
      "this at least as surprising.)\n",
      "\n",
      "Back to the question:\n",
      "\n",
      "If I had the resources to use a one-time-pad for such transmissions, I\n",
      "would also append a Message Authentication Code to the message, using up\n",
      "the next bits of the one-time-pad as the key perhaps. Your original\n",
      "question basically asked whether there was any way to authenticate the\n",
      "message with the same degree of security as the Pad itself provided,\n",
      "and I don't know the answer. However, I would propose the following\n",
      "for discussion.\n",
      "\n",
      "Alice and Bob have an arbitrary number of secret, random bits to\n",
      "share, which Eve doesn't know. She finds them out (effectively) by\n",
      "knowing some P and the corresponding C. It is the fact that they\n",
      "CORRESPOND that causes the problem. If a message authentication code was to\n",
      "be created using some one-time-pad operation such that Eve could not\n",
      "know which parts of the MAC were affected by which parts of the input,\n",
      "she would be unable to forge a MAC to correspond.\n",
      "\n",
      "What is required is a non-linear combiner of parts of the message.\n",
      "(Non-linear so that simply xoring or subtracting or whatever doesn't\n",
      "have exactly the same effect).\n",
      "\n",
      "Now, at the end of the encrypted message C, Alice appends a n-bit MAC\n",
      "computed as follows (S2 means the next full chunk of the one time pad):\n",
      "  1. compute C2 = P xor S2, and pad to an n-bit boundary with more of S\n",
      "  2. break C2 into n-bit chunks\n",
      "  3. set MAC to 0 (initialisation vector)\n",
      "  4. for i in each chunk sequentially\n",
      "       set MAC = MAC NLOP C2[i]\n",
      "\n",
      "At the end of this process MAC is the Message Authentication Code.\n",
      "\n",
      "(Bob verifies the MAC in the obvious manner; he recovers the\n",
      "plaintext P, then uses some more of his pad to reproduce the MAC in\n",
      "the same manner.)\n",
      "\n",
      "NLOP is the non-linear operator, and there is the rub. The simplest\n",
      "non-linear operator I can think of is an S-box; that is, have a fixed\n",
      "(even published) permutation of the n-bit integers, an indexable table\n",
      "called Sbox, and use:\n",
      "  x NLOP y = x xor Sbox[y].\n",
      "\n",
      "Practically speaking, I think this solves your problem, as Eve never\n",
      "sees the intermediate output C2, and hence can't deduce S2 or perform any valid\n",
      "substitution on it.\n",
      "\n",
      "Also practically speaking, you want the MAC to be fairly large, say 32\n",
      "bits, but you might not want a 4 gigabyte (say) S-box, so you might\n",
      "work on 4 byte-sized S-boxes, but I think that is an irrelevant detail\n",
      "for the discussion at hand.\n",
      "\n",
      "Who will be first to point out my errors, or give me a pointer to some\n",
      "literature?\n",
      "--\n",
      "Greg Rose                 Australian Computing and Communications Institute\n",
      "ggr@acci.com.au                                              +61 18 174 842\n",
      "`Use of the standard phrase \"HIJACKED\" may be inadvisable' -- CAA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d60589-0f2a-4490-8201-87917f01f898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Firstly, an aside:\n",
      "\n",
      "I agree that the weakness exists, but I have a lot of trouble\n",
      "believing that it represents a difficulty in real life. Given:\n",
      "\n",
      "1. the purpose of the one-time pad is to give unbreakable security,\n",
      "and the expense of key distribution etc., imply that the clients\n",
      "really do want that level of security\n",
      "\n",
      "2. These same people want to keep P a secret\n",
      "\n",
      "I find it hard to believe that Eve might happen to have a copy of P\n",
      "lying around.\n",
      "\n",
      "(I am aware that the same argument applies to Eve knowing even a small\n",
      "part of the message, but Eve must know EXACTLY where (which bytes) in\n",
      "C her known susequence starts, or the result will be garbled. I find\n",
      "this at least as surprising.)\n",
      "\n",
      "Back to the question:\n",
      "\n",
      "If I had the resources to use a one-time-pad for such transmissions, I\n",
      "would also append a Message Authentication Code to the message, using up\n",
      "the next bits of the one-time-pad as the key perhaps. Your original\n",
      "question basically asked whether there was any way to authenticate the\n",
      "message with the same degree of security as the Pad itself provided,\n",
      "and I don't know the answer. However, I would propose the following\n",
      "for discussion.\n",
      "\n",
      "Alice and Bob have an arbitrary number of secret, random bits to\n",
      "share, which Eve doesn't know. She finds them out (effectively) by\n",
      "knowing some P and the corresponding C. It is the fact that they\n",
      "CORRESPOND that causes the problem. If a message authentication code was to\n",
      "be created using some one-time-pad operation such that Eve could not\n",
      "know which parts of the MAC were affected by which parts of the input,\n",
      "she would be unable to forge a MAC to correspond.\n",
      "\n",
      "What is required is a non-linear combiner of parts of the message.\n",
      "(Non-linear so that simply xoring or subtracting or whatever doesn't\n",
      "have exactly the same effect).\n",
      "\n",
      "Now, at the end of the encrypted message C, Alice appends a n-bit MAC\n",
      "computed as follows (S2 means the next full chunk of the one time pad):\n",
      "  1. compute C2 = P xor S2, and pad to an n-bit boundary with more of S\n",
      "  2. break C2 into n-bit chunks\n",
      "  3. set MAC to 0 (initialisation vector)\n",
      "  4. for i in each chunk sequentially\n",
      "       set MAC = MAC NLOP C2[i]\n",
      "\n",
      "At the end of this process MAC is the Message Authentication Code.\n",
      "\n",
      "(Bob verifies the MAC in the obvious manner; he recovers the\n",
      "plaintext P, then uses some more of his pad to reproduce the MAC in\n",
      "the same manner.)\n",
      "\n",
      "NLOP is the non-linear operator, and there is the rub. The simplest\n",
      "non-linear operator I can think of is an S-box; that is, have a fixed\n",
      "(even published) permutation of the n-bit integers, an indexable table\n",
      "called Sbox, and use:\n",
      "  x NLOP y = x xor Sbox[y].\n",
      "\n",
      "Practically speaking, I think this solves your problem, as Eve never\n",
      "sees the intermediate output C2, and hence can't deduce S2 or perform any valid\n",
      "substitution on it.\n",
      "\n",
      "Also practically speaking, you want the MAC to be fairly large, say 32\n",
      "bits, but you might not want a 4 gigabyte (say) S-box, so you might\n",
      "work on 4 byte-sized S-boxes, but I think that is an irrelevant detail\n",
      "for the discussion at hand.\n",
      "\n",
      "Who will be first to point out my errors, or give me a pointer to some\n",
      "literature?\n"
     ]
    }
   ],
   "source": [
    "news_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), random_state=100)\n",
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17105a03-c335-4185-a028-b58e57eee1e4",
   "metadata": {},
   "source": [
    "## 학습 데이터 / 평가 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97904238-6bdb-401f-bd51-8fe30985955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 크기:11,314, 테스트 데이터 크기:7,532\n"
     ]
    }
   ],
   "source": [
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=100)\n",
    "x_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), random_state=100)\n",
    "x_test = test_news.data\n",
    "y_test = test_news.target\n",
    "\n",
    "print(f'학습 데이터의 크기:{len(x_train):,}, 테스트 데이터 크기:{len(x_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26e3ec-02b5-4b0d-8d0d-d436399eb6bd",
   "metadata": {},
   "source": [
    "## 피처 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe01396-62bb-497b-8b89-38641271bd05",
   "metadata": {},
   "source": [
    "### CountVectorizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85232fe7-56d3-403a-8230-d51ca00717dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "cnt_vect = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "cnt_vect.fit(x_train)  # 학습 데이터로 fit 하면 그것으로 사전을 만들고, 이와 동일한 기준으로 평가 데이터에도 transform 필요\n",
    "x_train_cnt_vect = cnt_vect.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bd40eb6-fd49-4758-8703-c6566c6e8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터로 fit()된 CounterVectorizer를 이용해서 테스트 데이터를 feature extraction 변환 수행\n",
    "x_test_cnt_vect = cnt_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e455d553-5289-42cd-9660-ba9be1cbf3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 텍스트의 vector shape: (11314, 101487)\n",
      "사전에 포함된 단어 개수: 101487\n"
     ]
    }
   ],
   "source": [
    "print(f'학습 데이터 텍스트의 vector shape: {x_train_cnt_vect.shape}')  # 11314 - 문장의 개수, 101487 - 단어의 개수\n",
    "print('사전에 포함된 단어 개수:', len(cnt_vect.vocabulary_))\n",
    "# print(x_train_cnt_vect[0][:10])    # (0 번째 데이터의 n번째 단어)의 n 빈도 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03357d-3245-4068-b399-98dfd3acba0b",
   "metadata": {},
   "source": [
    "### TfidfVectorizer 사용 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec105755-6221-4325-90e4-fe158f2812aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 값과 idf 값 곱해 만듦 = 영문서 빈도화\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf_vect = tfidf_vect.transform(x_train)\n",
    "x_test_tfidf_vect = tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd97002-424d-4895-8c2a-0cb8406cf928",
   "metadata": {},
   "source": [
    "### TfidfVectorizer 사용 -2\n",
    "- N-gram (1,2) 적용\n",
    "- max_df: 전체 문서에 걸쳐 너무 높은 빈도를 가지는 단어 피처 제외\n",
    "- min_df: 전체 문세에 걸쳐 낮은 빈도를 가지는 단어 피처 제외\n",
    "- ngram_range: 모델의 단어 순서를 어느 정도 보강하기 위한 범위 (범위 최솟값, 범위 최댓값)\n",
    ">- (1,2)로 하면 토큰화된 단어를 1개씩, 그리고 순서대로 2개씩 묶어서 피처로 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36115050-c6cf-4671-b4ec-499ff4b11941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(x_train)\n",
    "x_train_tfidf_vect = tfidf_vect.transform(x_train)\n",
    "x_test_tfidf_vect = tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab41f6ac-b363-4770-823a-ad03c3a3a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990299\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf_vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a604f-3b51-4237-a82b-a81e6025af58",
   "metadata": {},
   "source": [
    "## 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0026d3e1-5e04-4ec1-b7dc-034b1d458b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(x_train_cnt_vect, y_train)\n",
    "\n",
    "y_hat = lr_clf.predict(x_test_cnt_vect)\n",
    "print(f'정확도:{accuracy_score(y_test, y_hat):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18058ab1-eddc-4e71-b751-a082b7f2e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.688\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(x_train_tfidf_vect, y_train)\n",
    "\n",
    "y_hat = lr_clf.predict(x_test_tfidf_vect)\n",
    "print(f'정확도:{accuracy_score(y_test, y_hat):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fb513-8d6a-4a98-9f34-94bcdfe035b2",
   "metadata": {},
   "source": [
    "## 하이퍼 파라메터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cc1ac64-81fa-42b9-a6e5-932377c095c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라메터: {'C': 10}\n",
      "정확도:0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy')\n",
    "grid_cv_lr.fit(x_train_tfidf_vect, y_train)\n",
    "print('최적 파라메터:', grid_cv_lr.best_params_)\n",
    "y_hat = grid_cv_lr.best_estimator_.predict(x_test_tfidf_vect)\n",
    "print(f'정확도:{accuracy_score(y_test, y_hat):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
